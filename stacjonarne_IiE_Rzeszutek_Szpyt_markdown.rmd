---
title: "Projekt zaliczeniowy"
author: "Katarzyna Rzeszutek, Karol Szpyt"
date: "19 stycznia 2020"
output: 
  html_document:
    toc: true
    toc_depth: 4
encoding: "utf - 8"
    
---
Dane z jakich korzystano w poniższym opracowaniu to zestaw 19. **Celem niniejszego projektu jest budowa jak najlepiej dopasowanego modelu do danych, jego weryfikacja oraz przeprowadzenie predykcji.**


###Część empiryczna
#### 1. Transformacje na zbiorze danych
Początkowo wczytamy dane i biblioteki oraz przyględniemy się jak wyglądają początkowe obserwacje
```{r echo=TRUE, message=FALSE, warning=FALSE}
library(fastDummies)
library(kableExtra)
library(dplyr)
library(psych)
library(ggplot2)
library(gridExtra)
library(lmtest)
library(car)
library(tseries)
library(normtest)
library(strucchange)
data <-read.csv("IiE20192020dataset19.csv", sep = ";")
data[c(1:10),] %>% 
  kable() %>%
  kable_styling(bootstrap_options = "striped", "hover")
```
Wszystkie zmienne poza $X_7$ (która jest zmienną jakościową) są zmiennymi ilościowymi. Nasze dane posiadają także braki, dlatego należy się tym zająć. Sprawdzimy ile obserwacji ma wartości NA.
```{r echo=TRUE, message=FALSE, warning=FALSE}
sum(is.na(data))
```
Z całego zbioru 1000 obserwacji tylko 24 ma wartości NA. Jest to mniej niż 3%, zatem usuniemy te obserwacje z naszego zbioru danych

```{r message=FALSE, warning=FALSE, include=FALSE}
data <- na.omit(data)
```
Zajmiemy się teraz zmienną $X_7$, która jest jakościowa. W celu jej analizy zamienimy ją na szereg zmiennych zero - jedynkowych. Taka zmienna przyjmuje wartość jeden, gdy jakies zjawisko wystepuje i zero w przeciwnym przypadku. Jednak wprowadzenie takich zmiennych powoduje powstanie zjawiska współliniowości (dummy variable trap). Aby temu zapobiec należy nie brać pod uwage jednej kategorii, zazwyczaj robi się to dla tej, która ma najwięcej obserwacji. Zmienna C jest najczęściej przyjmowaną wartością, dlatego to jej sie pozbędziemy.

```{r echo=FALSE, message=FALSE, warning=FALSE}
dmmy <- dummy_cols(data$X7)
sum(dmmy$.data_A == 1)
sum(dmmy$.data_B == 1)
sum(dmmy$.data_C == 1)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
data <- cbind(data, dmmy)
data <- data[,-c(8,9,12)]
colnames(data)[8:9] <- c("A", "B") 

data[, -c(8, 9)] <- as.data.frame(lapply(as.list(data[, -c(8, 9)]), as.numeric))
```

###2. Podział próbki na zbiór uczący i testowy 
Dokonamy teraz podziału danych na zbiór uczący i testowy. Jakoże nie mamy już 1000 danych, tylko 976 to podział zostawimy w takich samych proporcjach jak zostało to zadane (proporcje 1:3)
```{r echo=TRUE, message=FALSE, warning=FALSE}
set.seed(293487)
train.inx <- sample(1:976, 732)
data.train <- data[train.inx,]
data.test <- data[-train.inx,]
```

###3. Prezentacja i opis danych.
Sprawdzimy teraz statystyki naszych danych, poza danymi jakościowymi
```{r echo=FALSE, message=FALSE, warning=FALSE}
wsp.zm <- function(dat) 
{
  sd(dat)/mean(dat)
}
zm.df <- t(as.data.frame(lapply(as.list(data.train[, -c(8, 9)]), wsp.zm)))
colnames(zm.df) <- "wsp.zm"
zm.df <- rbind(zm.df, NA, NA)
rownames(zm.df) <- colnames(data.train)

cbind(describe(data.train)[c(3, 4, 11, 12)], zm.df) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped")
```

Średnia zmiennej objaśnianej wynosi 496.42, przy medianie równej 498.5 i odchyleniu standardowym 289.40. Skośność wynosi 0, co świadczy o braku asymetrii wyników - obserwacje są symetrycznie rozłożone. Kurtoza osiąga wartość -1.24 - w każdej ze zmiennych występuje ujemna, więc słaba koncentracja wyników wokół średniej, czyli można powiedzieć, że część wyników każdej ze zmiennych jest oddalona od średniej. Zmienność tej zmiennej jest na poziomie 58%, co jest poprawnym stopniem.
  
  Zmienna X1 ma średnią o wartości 500.44,  przy medianie 503.5 i odchyleniu 287.23. Skośność na poziomie - 0.01 świadczy o delikatnej asymetrii w lewo, czyli nieznacznie więcej obserwacji jest większa od średniej. Zmienność osiąga poziom 57%.
  
  Zmienna X2 osiąga średnią 500.60, medianę 514 a odchylenie standardowe 283.43. Skośność jest ponownie nieznacznie mniejsza od zera.
  
  Zmienna X3 ma średnią 500.91, a mediana 496. Odchylenie standardowe wynosi 289.75. Skośność na poziomie 0.01 świadczy o delikatnym odchyleniu obserwacji w prawo. Zmienna osiąga poziom 58%.
  
  Zmienna X4 osiąga średnią 489.62, medianę 489.5 i odchylenie 291.18. Skośnośc wskazuje na delikatne odchylenie danych poniżej średniej. Współczynnik zmienności jest na poziomie 59%.
  
  Zmienna X5 ma średnią w wielkości 496.71, przy medianie 486.5 i odchyleniu 287.98. Skośność na poziomie 0.04 świadczy o odchyleniu obserwacji poniżej średniej. Współczynnik zmienności jest na poziomie 58%.
  
  Zmienna X6 osiąga średnią w wysokości 500.70. Odchylenie standardowe wynosi 289.24. Skośność wskazuje, że nieznaczne więcej obserwacji powyżej średniej.

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE}
gg.list <- list()
for (x in 1:(length(data.train) - 2)) {
  # plot(data.train[, x], type = "l", main = as.character(x), ylab = paste0("Y", as.character(x)))
  gg.list[[x]] <- data.train %>%
    ggplot(aes(x = 1:732)) +
    geom_line(aes_q(y = as.name(names(data)[x])))
  
  # print(gg)
}
grid.arrange(gg.list[[1]], 
             gg.list[[2]], 
             gg.list[[3]], 
             gg.list[[4]], 
             gg.list[[5]],
             gg.list[[6]], 
             gg.list[[7]], ncol = 2)  

```

###4. Dobór zmiennych do modelu
  
  Opierając się na metodach Hellwiga i krokowej wstecz sprawdzimy, które zmienne zostaną wybrane do modelu. Następnie sprawdzimy jak sie one prezentują 

```{r echo=TRUE, message=FALSE, warning=FALSE}
#metoda Hellwiga
source("Hellwig Method.R")
hellwig(data.train[, 1], data.train[, -1])

#metoda krokowa wstecz
model <- lm(Y ~ ., data.train)
step(model, direction = 'backward')
```
Metoda Hellwiga wskazuje na wybranie zmiennych A i B, natomiast metoda krokowa na zmienne X1, X3, X4, X5, A i B. **Zdecydowaliśmy, że będziemy działać na obu modelach w dalszej części projektu i po kolei je weryfikować, aż dojdziemy do satysfakcjonującej postaci.**
  
  
  Sprawdzimy rozkład reszt w obu tych modelach testami Shapiro - Wilka i Jarque - Bera. Hipotezy:
  
  *H0: rozkład badanej cechy jest rozkładem normalnym*
   
  
  *H1: rozkład badanej cechy nie jest rozkładem normalnym*

```{r echo=FALSE, message=FALSE, warning=FALSE}
model_hel <- lm(Y ~ A + B, data.train)
model_step <- lm(Y ~ X1 + X3 + X4 + X5 + A + B, data.train)
shapiro.test(model_hel$residuals)
jarque.bera.test(model_hel$residuals)
shapiro.test(model_step$residuals)
jarque.bera.test(model_step$residuals)
```

Żaden z tych modeli nie ma normalnego rozkładu reszt według testu Shapiro - Wilka, jednak według testu Jarque - Bera resztą są z rozkładu normalnego. oto ich wykresy
```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE}
plot(density(model_step$residuals))
plot((density(model_hel$residuals)))
```
**Mimo rozbieżności w wynikach obu testów założymy, że reszty naszego modelu mają asymptotyczny rozkład normalny, ze względu na dużą próbę.** Sprawdzimy kolejne założenia jakie powinien spełniać model, mianowicie: istotność zmiennych, istotność współczynnika determinacji $R^2$, koincydencja, poprawna postać funkcyjna modelu, brak współliniowości oraz stabilność parametrów. Weryfikacji ulegną model sugerowany przez metodę Hellwiga i krokową wstecz
  
  **Model metody Hellwiga**
```{r echo=FALSE, message=FALSE, warning=FALSE}
summary(model_hel)
```
**W modelu wskazanym przez metodę Hellwiga wszystkie zmienne są istotne**. Oceniliśmy to na podstawie testu t-Studenta (który ma założenie o normalności rozkładu reszt), a jego hipotezy to:
  
  *H0: dana zmienna nie oddziałuje istotnie na zmienną objaśnianą*
  
  *H1: dana zmienna oddziałuje istotnie na zmienną objaśnianą.*

**Model wyjaśnia tylko 0.25 zmiennej zależnej** - współczynnik $R^2$. Niestety jest to bardzo niski poziom 
  
  Sprawdzimy czy wielkość współczynnika determinacji jest statystycznie istotna. Użyjemy do tego testu Fishera - Snedecora, który służy do badania istotności współczynnika korelacji wielorakiej. Hipotezy:
  
  *H0: współczynnik korelacji wielorakiej jest równy 0 - nieistotny*
  
  *H1: współczynnik korelacji wielorakiej jest większy od 0 - istotny*
  
  Wartość p-value dla tego testu wskazuje na odrzucenie $H_0$ - **współczynnik determinacji $R^2$ jest istotny**.
  
  Sprawdzimy koincydencję. W tym celu sprawdzamy czy spełniony jest warunek 
$$sgn(r_{i}) = sgn(a_{i})$$ gdzie i = 1,2,,,,k. 
  
  $a_{i}$ to oszacowanie parametru strukturalnego występującego przy zmiennej objaśniającej $X_{i}$, a $r_{i}$ jest współczynnikiem korelacji liniowej Pearsona między zmienną $X_{i}$ a $Y_{i}$
```{r echo=FALSE, message=FALSE, warning=FALSE}
korelacje <- cor(data.train, method = "pearson")
korelacje[1,c(8,9)]
model_hel
```
**Model wynikający z metody Hellwiga jest koincydentny**, gdyż parametr stojący przy zmiennej $B$ jest ujemny, tak samo jak współczynnik korelacji liniowej tej zmiennej z $Y$.
  
  Sprawdzimy poprawność funkcyjną modelu testem RESET. Hipotezy:
  
  *H0: wybór postaci analitycznej modelu jest prawidłowy,*
  
  *H1: wybór postaci analitycznej modelu nie jest prawidłowy,*
```{r echo=FALSE, message=FALSE, warning=FALSE}
resettest(model_hel)
```
Model wybrany na podstawie metody Hellwiga ma poprawną powstać funkcyjną modelu, a więc jego **postać (liniowa) jest poprawna**.

```{r echo=FALSE, message=FALSE, warning=FALSE}
vif(model_hel)
```
Współliniowość oceniamy *czynnikiem inflacji wariancji* (VIF). Wskaźnik ten pokazuje ile razy wariancja predyktora jest większa od wartości niezakłóconej współliniowością, gdzie 1 jest najmniejszą możliwą wartością, a 10 największą. **W modelu wybranym na podstawie metody Hellwiga nie ma zjawiska współliniowości**.
  
  Stabilność parametrów sprawdzimy za pomocą testu Chowa. Służy do weryfikacji czy parametry modelu będą takie same dla kilku różnych podpróbek. Hipotezy:
  
  *H0: parametry są takie same w podpróbkach - są stabilne*
  
  *H1: parametry nie są takie same w podpróbkach - nie są stabilne*
```{r echo=FALSE, message=FALSE, warning=FALSE}
sctest(model_hel, type = "chowa")
```
Wynik wskazuje na przyjęcie $H_0$ - **parametry tego modelu są stabilne**.
  
  Sprawdzimy założenie MNK o stałości wariancji składnika losowego modelu. Zobaczmy jak reszty prezentują się na wykresie
```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
plot(residuals(model_hel), type = "l")
```
Wykres reszt wskazuje na występowanie heteroskedastyczności, ale dla pewności uruchomiony zostanie test Breuscha - Pagana oraz , którego hipotezy to:
  
  *H0: homoskedastyczność*
  
  *H1: heteroskedastyczność* Zalezy co wyjdzie mi z WMNK jak wyjdzie chujowo to napisz ze tu jest homo, jakwyjdzie spoko to napisz ze jest hetero i stosuj ten z ważonej
  
  **Model metody krokowej wstecz**
```{r echo=FALSE, message=FALSE, warning=FALSE}
summary(model_step)
```
W modelu sugerowanym przez metodę krokową wstecz $X_5$ okazała się nieistotna - pozbędziemy się jej z modelu.
```{r echo=FALSE, message=FALSE, warning=FALSE}
model_step <- lm(Y ~ X1 + (X3) + (X4)  + A + B, data.train)
summary(model_step)
```
**Model wyjaśnia tylko 0.28 zmienności zmiennej zależnej - $R^2$, mimo tego współczynnik determinacji (jak i wszystkie zmienne) jest istotny**.
  
  Sprawdzimy koincydencję
```{r echo=FALSE, message=FALSE, warning=FALSE}
korelacje <- cor(data.train, method = "pearson")
korelacje[1,c(2,4,5,8,9)]
model_step
```
Model wynikający z metody krokowej jest koincydentny.
  
  Sprawdzimy poprawność funkcyjną modelu
```{r echo=FALSE, message=FALSE, warning=FALSE}
resettest(model_step)
```
Niestety nasz model nie ma poprawnej postaci funkcyjnej, zatem postać liniowa nie będzie dla niego właściwa. Należy dokonać pewnych tranformacji w celu uzyskania poprawnej postaci modelu. Będziemy próbować róznych postaci modelu i od razu prezentować wyniki jakie pokazał test RESET, w celu znalezienia poprawnej postaci
```{r echo=TRUE, message=FALSE, warning=FALSE}
#Logarytmy
#logarytm zmiennej objaśnianej
model_step <- lm(log(Y) ~ X1 + X3 + X4  + A + B, data.train)
resettest(model_step)
#logarytm wszystkich zmiennych (oprócz zmiennych jakościowych)
model_step <- lm(log(Y) ~ log(X1) + log(X3) + log(X4)  + A + B, data.train)
resettest(model_step)
#logarytmy tylko zmiennych objaśniających
model_step <- lm(Y ~ log(X1) + log(X3) + log(X4)  + A + B, data.train)
resettest(model_step)

#Podniesienie do potęgi drugiej
#zmiennej objaśnianej
model_step <- lm((Y)^2 ~ X1 + X3 + X4  + A + B, data.train)
resettest(model_step)
#wszystkich zmiennych (oprócz zmiennych jakościowych)
model_step <- lm((Y)^2 ~ (X1)^2 + (X3)^2 + (X4)^2  + A + B, data.train)
resettest(model_step)
#wszystkich zmiennych
model_step <- lm((Y)^2 ~ (X1)^2 + (X3)^2 + (X4)^2  + A^2 + B^2, data.train)
resettest(model_step)
#tylko zmiennych objaśniających (bez jakościowych)
model_step <- lm(Y ~ (X1)^2 + (X3)^2 + (X4)^2  + A + B, data.train)
resettest(model_step)
#tylko zmiennych objaśniających
model_step <- lm(Y ~ (X1)^2 + (X3)^2 + (X4)^2  + A^2 + B^2, data.train)
resettest(model_step)

#Podniesienie do potęgi trzeciej
#zmiennej objaśnianej
model_step <- lm((Y)^3 ~ X1 + X3 + X4  + A + B, data.train)
resettest(model_step)
#wszystkich zmiennych (oprócz zmiennych jakościowych)
model_step <- lm((Y)^3 ~ (X1)^3 + (X3)^3 + (X4)^3  + A + B, data.train)
resettest(model_step)
#wszystkich zmiennych
model_step <- lm((Y)^3 ~ (X1)^3 + (X3)^3 + (X4)^3  + A^3 + B^3, data.train)
resettest(model_step)
#tylko zmiennych objaśniających (bez jakościowych)
model_step <- lm(Y ~ (X1)^3 + (X3)^3 + (X4)^3  + A + B, data.train)
resettest(model_step)
#tylko zmiennych objaśniających
model_step <- lm(Y ~ (X1)^3 + (X3)^3 + (X4)^3  + A^3 + B^3, data.train)
resettest(model_step)

#Pierwiastki
#zmiennej objaśnianej
model_step <- lm(sqrt(Y) ~ X1 + X3 + X4  + A + B, data.train)
resettest(model_step)
#wszystkich zmiennych (oprócz zmiennych jakościowych)
model_step <- lm(sqrt(Y) ~ sqrt(X1) + sqrt(X3) + sqrt(X4)  + A + B, data.train)
resettest(model_step)
#tylko zmiennych objaśniających
model_step <- lm(Y ~ sqrt(X1) + sqrt(X3) + sqrt(X4)  + A + B, data.train)
resettest(model_step)
```
Niestety po mimo podjętych prób nie udało się znależć poprawnej postaci funkcyjnej modelu wskazanego przez metodę zmiennej krokowej.
  
  Sprawdzimy jeszcze założenie o stałości wariancji składnika losowego w obu modelach - dla modelu wskazanego przez metodę step przez jakimikolwiek tranformacjami, czyli :
```{r echo=TRUE, message=FALSE, warning=FALSE}
model_step <- lm(Y ~ X1 + (X3) + (X4)  + A + B, data.train)
model_step
```
  
```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align='center'}
plot(residuals(model_step), type = "l")
plot(residuals(model_hel), type = "l")
```
Wykres reszt obu modeli wskazuje na występowanie heteroskedastyczności, ale dla pewności uruchomiony zostanie test Breuscha-Pagana (w 2 odłonach - *bptest* i *ncvTest*) oraz Goldfelda-Quandta, których hipotezy to:
  
  *H0: homoskedastyczność składnika losowego*
  
  *H1: heteroskedastyczność składnika losowego*
```{r echo=FALSE, message=FALSE, warning=FALSE}
bptest(model_hel)
bptest(model_step)
ncvTest(model_hel)
ncvTest(model_step)
gqtest(model_hel)
gqtest(model_step)
```
Testy Breuscha - Pagana raz odrzucają $H_0$ a raz przyjmują dla każdego z modeli, gdzie test Goldfelda-Quandta wskazuje na przyjęcie hipotezy o homoskedastyczności w obu modelach. Na tej podstawie można by sądzić, że modele są homoskedastyczne. 
  
  Jednak wiemy już, że model wskazany metodą krokową nie ma poprawnej postaci funkcyjnej, dlatego spróbujemy zająć się zjawiskiem heteroskedastyczności. Mimo tego, że 2 testy wskazały na jej brak, patrząc na wykres reszt mamy co do tego wątpliwości, dlatego spróbujemy wyestymować ten model jeszcze raz, tym razem uzywająć ważonej metody najmniejszych kwadratów i sprawdzimy czy znajdziemy poprawną postać funkcyjną oraz czy inne założenie poprawnego modelu będą spełnione.
  
  Jeśli chodzi o model wskazany metodą Hellwiga także mamy wątpliwości co do homoskedastyczności rozkładu reszt i też spróbujemy wyestymować ten model ważoną MNK, mimo że model przeszedł poprawnie wszystkie testy. Nie wiemy czy takie podejście jest prawidłowe, ale zaryzykujemy i sprawdzimy to:)

# Ważona MNK
Aby ominąć problem heteroskedastyczności użyta zostanie ważona metoda najmniejszych kwadratów. Pozwala ona nadać obserwacjom o niskiej wariancji składnika losowego większe wagi, a tym które mają ją zbyt wysoką mniejsze wagi. W ten sposób eliminuje się niekorzystny wpływ zakłócających obserwacji na otrzymane oceny estymatorów. Oceny parametrów są liniowymi, zgodnymi, nieobciążonymi i najefektywniejszymi szacunkami parametrów strukturalnych modelu.
  
  W tym celu stworzymy model pomocniczy, gdzie zmienną objaśnianą są reszty z poprzedniego modelu (wartość bezwzględna), a zmiennymi objaśniającymi będą zmienne z poprzedniego modelu
```{r echo=TRUE, message=FALSE, warning=FALSE}
#model pomocniczny - zmienna objaśniana to wartość bezwględna z reszt a zmienne objaśniające to zmienne objaśniające z poprzedniego modelu
model.helpmegod_hel <- lm(abs(residuals(model_hel)) ~ A + B, data.train)
model.helpmegod_step <- lm(abs(residuals(model_step)) ~ X1 + X3 + X4 + A + B, data.train)
```

Na podstawie powyższego modelu wyliczone zostaną reszty
```{r echo=TRUE, message=FALSE, warning=FALSE}
#wagi
wages_hel <- (model.helpmegod_hel$fitted.values)^-2
wages <- (model.helpmegod_step$fitted.values)^-2

#ważona mnk
model.wg_hel <- lm(Y ~ A + B, data.train, weights = wages_hel)
model.wg <- lm(Y ~ X1 + X3 + X4 + A + B, data.train, weights=wages)
summary(model.wg_hel)
summary(model.wg)
```
# Badanie normalności rozkładu reszt, istotnych zmiennych, współczynnika determinacji i jego istotności
 W obu modelach ponownie zakładamy, że reszty asymptotycznie należą do rozkładu normalnego, ze względu na dużą próbę. W modelu zasugerowanym przez metodę Hellwiga wszystkie zmienne są istotne, współczynnik $R^2$ także jest istotny i wynosi on 0.69. W modelu podanym przez metodę regresji krokowej pozbędziemy się zmiennych $X_1$ i $X_3$, gdyż są one nieistotne.
  
  
```{r echo=FALSE, message=FALSE, warning=FALSE}
model.wg <- lm(Y ~ X4 + A + B, data.train, weights=wages)
summary(model.wg)
```
Teraz wszystkie zmienne są istotne, współczynnik determinacji wynosi 0.69 i jest istotny.

#Badanie heteroskedastyczności modelu z regresji wstecznej
  Ważona MNK nie likwiduje heteroskedastyczności, ale minimalizuje jej wpływ na poprawność oszacowań parametrów. Dlatego sprawdzimy co pokazują testy
```{r echo=FALSE, message=FALSE, warning=FALSE}
bptest(model.wg)
bptest(model.wg_hel)
```
W obu modelach nadal występuje heteroskedastyczność, jednak nie będzie to już wpływało na estymatory.
#Badanie współliniowości, postaci funkcyjnej modelu i stabilności parametrów
Sprawdzimy zjawisko współliniowości. Oceniamy ją *czynnikiem inflacji wariancji - VIF*. Wskaźnik ten pokazuje ile razy wariancja predyktora jest większa od wartości niezakłóconej współliniowością, gdzie 1 jest najmniejszą możliwą wartością, a 10 największą
```{r echo=FALSE, message=FALSE, warning=FALSE}
vif(model.wg_hel)
```
Wartości A i B cechują się współliniowości, zatem musimy się pozbyć ich obu i ponownie sprawdzimy współliniowość
```{r echo=FALSE, message=FALSE, warning=FALSE}
model.wg <- lm(Y ~ X4, data.train, weights=wages)
#vif(model.wg)
```
Skoro ze współliniowścią nie ma już problemów, sprawdzimy **poprawność postaci funkcyjnej modelu testem RESET.** Hipotezy:
  
  *H0: wybór postaci analitycznej modelu jest prawidłowy,*
  
  *H1: wybór postaci analitycznej modelu nie jest prawidłowy,*

```{r echo=FALSE, message=FALSE, warning=FALSE}
resettest(model.wg_hel)
```
Odrzucamy $H_0$ - podana postać nie jest poprawna. Dokonamy kilku tranformacji i sprawdzimy jeszcze raz poprawność postaci modelu
  
```{r echo=TRUE, message=FALSE, warning=FALSE}
model.wg <- lm(sqrt(Y) ~ sqrt(X4) + B, data.train, weights=wages)
resettest(model.wg)
```
Teraz przyjmujemy $H_0$ - **podana postać modelu jest prawidłowa**.  Sprawdzimy teraz stabilność parametrów
  
```{r echo=FALSE, message=FALSE, warning=FALSE}
harvtest(model.wg)
```
  
  *H0: parametry są stabilne*
  
  *H0: parametry nie są stabilne*
```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(model.wg)
```
  
$R^2$ modelu wynosi 0.61 - nie jest to oszałamiający wynik, ale wystarczający do przeprowadzenia na nim prognox.
  
```{r}

```

  
  
  
  
  
  
#Dlaczego jeden test pokazuje ze są hetero, a 3 testy że są homo?
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
